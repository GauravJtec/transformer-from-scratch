{

 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9854f02a-a25c-4df4-a0cb-b1ef52ec34b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf0bd19e-8f10-40ff-a852-8f3bec9ac2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length=4\n",
    "batch_size=1\n",
    "input_dim=512\n",
    "d_model=512\n",
    "x=torch.randn((batch_size,sequence_length,input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77642756-2737-4734-a417-79c3cc111271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e01aa3cc-39fc-403f-96e2-e28b94bed88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv_layer=nn.Linear(input_dim,3*d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d46e1d75-1bd8-4cee-bbd5-4a06abf67462",
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv=qkv_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4134384c-39d4-4a4b-bab2-9f8f9fdefae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 1536])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11ec4d16-7932-48c5-ae0e-431ca799cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads=8\n",
    "head_dim=d_model//num_heads\n",
    "qkv=qkv.reshape(batch_size,sequence_length,num_heads,3*head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a249596-3898-4fa1-9135-6575d590a449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 8, 192])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85039c93-a3b7-42fb-9ada-ee0b6bfe89fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 192])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv=qkv.permute(0,2,1,3)\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "494c1c87-0f1a-47a9-9f52-c238fe74f1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q,k,v=qkv.chunk(3,dim=-1)\n",
    "q.shape,k.shape,v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82dd3597-c717-49cd-9962-91ce2df156aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k=q.size()[-1]\n",
    "scaled=torch.matmul(q,k.transpose(-2,-1))/math.sqrt(d_k)\n",
    "scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d01d450-a2bd-44fa-ae87-b7879023b24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_9752\\3717780648.py:1: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3575.)\n",
      "  k.T.shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4, 8, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af2faaf8-ba6a-4b5a-9f7e-356b34c18313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf],\n",
       "        [0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask=torch.full(scaled.size(),float('-inf'))\n",
    "mask=torch.triu(mask,diagonal=1)\n",
    "mask[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d3f41e4-21c4-437f-9725-7261bf472fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1452,    -inf,    -inf,    -inf],\n",
       "        [-0.8340, -0.3321,    -inf,    -inf],\n",
       "        [ 0.0607, -0.0582, -0.1677,    -inf],\n",
       "        [-0.1937, -0.0726,  0.0258,  0.4228]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(scaled+mask)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26db9b49-ab16-4daa-ae99-ac1f7c979367",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled+=mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27ef403e-f468-4aac-b2b7-1270eacd9c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention=F.softmax(scaled,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9aec7998-b699-429d-91de-f469e1a78ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "values=torch.matmul(attention,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "088d8185-46b4-4b26-b7f4-8586b4c406e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def scaled_dot_product(q,k,v,mask=None):\n",
    "    d_k=q.size()[-1]\n",
    "    scaled=torch.matmul(q,k.transpose(-1,-2))/math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled+=mask\n",
    "    attention=F.softmax(scaled,dim=-1)\n",
    "    values=torch.matmul(attention,v)\n",
    "    return values,attention\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b6d2aa27-c9c2-44f5-9129-0fd877ac1922",
   "metadata": {},
   "outputs": [],
   "source": [
    "values,attention = scaled_dot_product(q, k,v, mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db616654-dcc3-465f-ae39-940273b204d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3379, 0.2101, 0.2154, 0.2366],\n",
       "        [0.1606, 0.2654, 0.2892, 0.2848],\n",
       "        [0.2300, 0.2042, 0.1830, 0.3827],\n",
       "        [0.1913, 0.2160, 0.2383, 0.3544]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "867b4095-7acf-440c-ba3c-fe446e34f8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03dbdade-3d16-4f97-8a51-3ee52c3c6082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values=values.reshape(batch_size,sequence_length,num_heads*head_dim)\n",
    "values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dbea51eb-9170-4579-9a97-cdb7f47e7c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer=nn.Linear(d_model,d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b95083b-eda5-4e8c-a1e0-58f5f976a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def scaled_dot_product(q,k,v,mask=None):\n",
    "    d_k=q.size()[-1]\n",
    "    scaled=torch.matmul(q,k.transpose(-1,-2))/math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled+=mask\n",
    "    attention=F.softmax(scaled,dim=-1)\n",
    "    values=torch.matmul(attention,v)\n",
    "    return values,attention\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self,imput_dim,d_model,num_heads):\n",
    "        super().__init__()\n",
    "        self.imput_dim=input_dim\n",
    "        self.d_model=d_model\n",
    "        self.num_heads=num_heads\n",
    "        self.head_dim=d_model//num_heads\n",
    "        self.qkv_layer=nn.Linear(input_dim,3*d_model)\n",
    "        self.linear_layer=nn.Linear(d_model,d_model)\n",
    "\n",
    "\n",
    "    def forward(self,x,mask=None):\n",
    "        batch_size,sequence_length,input_dim=x.size()\n",
    "        print(f\"x.size():{x.size()}\")\n",
    "        qkv=self.qkv_layer(x)\n",
    "        print(f\"qkv.size():{qkv.size()}\")\n",
    "        qkv=qkv.reshape(batch_size,sequence_length,num_heads,3*head_dim)\n",
    "        print(f\"qkv.size():{qkv.size()}\")\n",
    "        qkv=qkv.permute(0,2,1,3)\n",
    "        print(f\"qkv.size():{qkv.size()}\")\n",
    "        q,k,v=qkv.chunk(3,dim=-1)\n",
    "        print(f\"qsize:{q.size()},ksize:{v.size()},v size:{v.size()}\")\n",
    "        values,attention = scaled_dot_product(q, k,v, mask=None)\n",
    "        values=values.reshape(batch_size,sequence_length,num_heads*head_dim)\n",
    "        out=self.linear_layer(values)\n",
    "        print(f\"out.size():{out.size()}\")\n",
    "        return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc2746ca-5d47-4ab1-8f5f-a2c65eda462a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.size():torch.Size([30, 5, 1024])\n",
      "qkv.size():torch.Size([30, 5, 1536])\n",
      "qkv.size():torch.Size([30, 5, 8, 192])\n",
      "qkv.size():torch.Size([30, 8, 5, 192])\n",
      "qsize:torch.Size([30, 8, 5, 64]),ksize:torch.Size([30, 8, 5, 64]),v size:torch.Size([30, 8, 5, 64])\n",
      "out.size():torch.Size([30, 5, 512])\n"
     ]
    }
   ],
   "source": [
    "input_dim=1024\n",
    "d_model=512\n",
    "num_heads=8\n",
    "\n",
    "batch_size=30\n",
    "sequence_length=5\n",
    "x=torch.randn((batch_size,sequence_length,input_dim))\n",
    "model=MultiheadAttention(input_dim,d_model,num_heads)\n",
    "out=model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad699d3-19a8-47be-841b-ba96fef63be6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
